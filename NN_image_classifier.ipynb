{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Opt_su_leaky_relu.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzzvvAn5F0Ip",
        "outputId": "27ec8494-2482-4a06-844e-0a63f4fd847a"
      },
      "source": [
        "  import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/train.npy\", \"rb\") as f:\n",
        "    data = np.load(f)\n",
        "    images = data[\"images\"]\n",
        "    labels = data[\"labels\"]\n",
        "    f.close()\n",
        "  \n",
        "X_data = images / 255 - 0.5\n",
        "y_data = np.zeros((len(labels), 10))\n",
        "y_data[np.arange(len(labels)), labels] = 1.0\n",
        "\n",
        "# Shuffle the indices of our dataset\n",
        "rng = np.random.RandomState(5)\n",
        "indices = np.arange(len(X_data))\n",
        "rng.shuffle(indices)\n",
        "\n",
        "# Split the indices into two parts\n",
        "test_fraction = 0.001\n",
        "test_count = int(len(indices) * test_fraction)\n",
        "train_indices = indices[test_count:]\n",
        "test_indices = indices[:test_count]\n",
        "\n",
        "# Create the two datasets (training and testing) using our shuffled indices\n",
        "X_train = X_data[train_indices]\n",
        "y_train = y_data[train_indices]\n",
        "X_test = X_data[test_indices]\n",
        "y_test = y_data[test_indices]\n",
        "print(y_test.shape)\n",
        "X_orig = images[train_indices]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(73, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtQF1HYaF5Cx",
        "outputId": "2cb07d08-1bac-42ec-ff90-920cceb352cb"
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "def residual_layers(x, neuron_count=256):\n",
        "    skipping_input = x\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(neuron_count // 4, kernel_size=(1, 1), activation=tf.keras.layers.LeakyReLU(alpha=0.1), padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Conv2D(neuron_count // 4, kernel_size=(3, 3), activation=LeakyReLU(alpha=0.1), padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Conv2D(neuron_count, kernel_size=(1, 1), padding=\"same\")(x)\n",
        "\n",
        "    x = skipping_input + x\n",
        "    x = tf.keras.layers.Activation(LeakyReLU(alpha=0.1))(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "x = tf.keras.layers.Conv2D(64, kernel_size=(7, 7), activation=tf.keras.layers.LeakyReLU(alpha=0.1), padding=\"same\")(inputs)\n",
        "\n",
        "\n",
        "x = residual_layers(x, neuron_count=64)\n",
        "x = residual_layers(x, neuron_count=64)\n",
        "tf.keras.layers.BatchNormalization()\n",
        "tf.keras.layers.Dropout(0.5)\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation=tf.keras.layers.LeakyReLU(alpha=0.1), padding=\"same\")(x)\n",
        "#x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x) Neverta antro poolingo\n",
        "x = residual_layers(x, neuron_count=128)\n",
        "x = residual_layers(x, neuron_count=128)\n",
        "tf.keras.layers.BatchNormalization() # BN VEIKIA GERIAU PRIES DROPOUT\n",
        "tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation=tf.keras.layers.LeakyReLU(alpha=0.1), padding=\"same\")(x)\n",
        "x = residual_layers(x, neuron_count=256)\n",
        "x = residual_layers(x, neuron_count=256)\n",
        "tf.keras.layers.BatchNormalization()\n",
        "tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "#x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(x) Trecio irgi\n",
        "\n",
        "#x = tf.keras.layers.GlobalAveragePooling2D()(x) Global neapsimoka\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "class CIFAR10Sequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.rng = np.random.RandomState(0)\n",
        "        self.indices = np.arange(len(self.x))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        self.transform_rng = np.random.RandomState(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[batch_indices]\n",
        "        batch_y = self.y[batch_indices]\n",
        "\n",
        "        for i in range(len(batch_x)):\n",
        "            angle = self.transform_rng.uniform(-25, 25)\n",
        "            batch_x[i] = scipy.ndimage.rotate(batch_x[i], angle, reshape=False, mode=\"reflect\")\n",
        "\n",
        "            shift_x = self.transform_rng.randint(-2, 3)\n",
        "            shift_y = self.transform_rng.randint(-2, 3)\n",
        "\n",
        "            batch_x[i] = scipy.ndimage.shift(batch_x[i], (shift_x, shift_y, 0), mode=\"reflect\")\n",
        "\n",
        "        return batch_x / 255 - 0.5, batch_y#  / 255 - 0.5\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.rng.shuffle(self.indices)\n",
        "\n",
        "generator = CIFAR10Sequence(X_orig, y_train, batch_size=256)\n",
        "\n",
        "  \n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "def step_decay(epoch):\n",
        "    lr = 0.0006 * 0.94 ** epoch\n",
        "    print(f\"Current learning rate: {lr} in epoch: {epoch}\")\n",
        "    return lr\n",
        "\n",
        "model.fit(generator, batch_size=256, epochs=30) # kol kas be step decay"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   9472        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   1040        conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1088        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 32, 32, 64)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   1040        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   1088        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 32, 32, 64)   0           activation[0][0]                 \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 128)    73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 32)     4128        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 32)     9248        conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 128)    4224        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 8, 8, 128)    0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 128)    0           tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 32)     4128        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 8, 8, 32)     9248        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 128)    4224        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 8, 8, 128)    0           activation_2[0][0]               \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 128)    0           tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 256)    295168      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     16448       conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 256)    16640       conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 8, 8, 256)    0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 256)    0           tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 256)    16640       conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 8, 8, 256)    0           activation_4[0][0]               \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 256)    0           tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 16384)        0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           163850      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 726,474\n",
            "Trainable params: 726,474\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "286/286 [==============================] - 908s 3s/step - loss: 1.7507 - accuracy: 0.3802\n",
            "Epoch 2/30\n",
            "286/286 [==============================] - 907s 3s/step - loss: 0.5084 - accuracy: 0.8425\n",
            "Epoch 3/30\n",
            "286/286 [==============================] - 906s 3s/step - loss: 0.3755 - accuracy: 0.8856\n",
            "Epoch 4/30\n",
            "286/286 [==============================] - 906s 3s/step - loss: 0.3181 - accuracy: 0.9055\n",
            "Epoch 5/30\n",
            "286/286 [==============================] - 903s 3s/step - loss: 0.2881 - accuracy: 0.9137\n",
            "Epoch 6/30\n",
            "286/286 [==============================] - 904s 3s/step - loss: 0.2688 - accuracy: 0.9208\n",
            "Epoch 7/30\n",
            "286/286 [==============================] - 899s 3s/step - loss: 0.2535 - accuracy: 0.9237\n",
            "Epoch 8/30\n",
            "286/286 [==============================] - 900s 3s/step - loss: 0.2406 - accuracy: 0.9298\n",
            "Epoch 9/30\n",
            "286/286 [==============================] - 921s 3s/step - loss: 0.2281 - accuracy: 0.9324\n",
            "Epoch 10/30\n",
            "286/286 [==============================] - 910s 3s/step - loss: 0.2193 - accuracy: 0.9369\n",
            "Epoch 11/30\n",
            "286/286 [==============================] - 909s 3s/step - loss: 0.2068 - accuracy: 0.9395\n",
            "Epoch 12/30\n",
            "286/286 [==============================] - 901s 3s/step - loss: 0.2038 - accuracy: 0.9405\n",
            "Epoch 13/30\n",
            "286/286 [==============================] - 898s 3s/step - loss: 0.1969 - accuracy: 0.9422\n",
            "Epoch 14/30\n",
            "136/286 [=============>................] - ETA: 7:50 - loss: 0.1831 - accuracy: 0.9471"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Cw41FSGSUT"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
        "\n",
        "print(f\"Train accuracy = {accuracy:.4f}\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Test accuracy = {accuracy:.4f}\")\n",
        "\n",
        "import numpy as np\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/test.npy\", \"rb\") as f:\n",
        "    duom = np.load(f)\n",
        "    XX_test = duom[\"images\"]\n",
        "    f.close()\n",
        "\n",
        "XX_test = XX_test / 255 - 0.5\n",
        "Prediction = model.predict(XX_test, verbose=2)\n",
        "Prediction = tf.argmax(Prediction, axis=1)\n",
        "print(Prediction)\n",
        "Prediction = pd.DataFrame(Prediction).to_csv('/content/drive/MyDrive/Colab Notebooks/PredictionLeakySUADAM.csv', header=None, index=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}